# Featured in Neptune.ai's State of Foundation Model Training Report 2025

# 0. Background

I was recently featured in [Neptune.ai's State of Foundation Model Training Report 2025](https://neptune.ai/state-of-foundation-model-training-report). The report is based on interviews with folks like me who are actually building foundation models across different industries—not just the big frontier labs we always hear about.

The study cuts through the PR shell to show what companies are really doing when training their own models. They talked to teams from financial services, healthcare, manufacturing, and research x from startups to big enterprises.

**Key findings that resonated with me:**
- Companies train foundation models for highly specialized problems and compliance requirements
- There's a shift from carefully curated datasets to tapping diverse raw data sources
- Foundation model teams need to be multi-disciplinary with strong data and software engineering focus
- Success comes from early proof-of-concept projects and staying focused on core objectives

# 1. Our Perspective: Building Biomedical Foundation Models

As part of the study, I shared our experience building foundation models at Prescient-FM (formerly Prescient-LM) within Genentech's Prescient Design platform. Here are some key insights that were highlighted:

## Why Train Our Own Models?

> *"In the therapeutic domain, the current so-called 'frontier LLMs' are still pretty far below the bar, and our highly specialized tasks are really not their top priorities. There are a lot more low-hanging (yet pretty challenging) fruits for leading players like OpenAI and Anthropic to pick than fully understanding biology, physiology, and health.*
> 
> *So if your company has been collecting a huge amount of private data for a challenging task, you have a good reason to train your own models and to learn a lot by doing so. The expertise you'll have acquired will be totally worth it. First-hand experience is the best teacher in this area, and the better you understand LLMs, the better you set your strategy and build state-of-the-art tools.*
> 
> *There's always skepticism about training our own model, arguing we should outsource it. If biomedical science is going to be solved by the next GPT, then yes, perhaps they're right. But no, it's going to take a very long time, and we definitely need to grow our expertise unless we're going to be happy with relying on commoditized knowledge and tools – in which case, I have no idea how we can differentiate ourselves from others and win the competition."*

## Balancing Optimization with Progress

> *"It's tempting to focus on infrastructure optimization because it is easy to put numbers on it. However, there are often more important goals the team should focus on, even if they are harder to measure and quantify. We'll sometimes have to leave some GPU utilization on the table to make progress."*

# 2. Video Insights: Behind the Scenes

Neptune.ai also created a series of videos featuring our insights. Here are the four videos that dive deeper into various aspects of our foundation model training journey:

## Key Lessons from LLM Training
<iframe width="560" height="315" src="https://www.youtube.com/embed/v-zudK5KnWY?si=f7BZyGd_1_S7zS3F" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

## Why We're Building Foundation Models at Genentech  
<iframe width="560" height="315" src="https://www.youtube.com/embed/SBV5VTQrlDs?si=R6EPVdo7GU1ZNklI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

## Challenges in Training Biomedical LLMs
<iframe width="560" height="315" src="https://www.youtube.com/embed/4zGIRsnrTk8?si=jh8fd0OE549yrFn1" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

## Infrastructure and GPU Challenges
<iframe width="560" height="315" src="https://www.youtube.com/embed/eIj_DNemEyg?si=r-hy5FBw_00ssXRt" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

# 3. Reflections and Key Takeaways

Being part of this report provided an opportunity to reflect on our journey building internal LLMs for therapeutic applications. A few key takeaways:

**Domain expertise is irreplaceable.** While general-purpose LLMs continue to improve, the specialized knowledge required for biomedical applications creates a clear competitive moat for organizations willing to invest in domain-specific models.

**Building internal capabilities matters.** The expertise gained from training your own models compounds over time, enabling better strategic decisions and more sophisticated applications.

**Small teams can make big impact.** You don't need massive scale to meaningfully contribute to the foundation model landscape—focused teams with clear objectives and domain expertise can achieve remarkable results.

# 4. Looking Forward

The foundation model landscape continues to evolve rapidly, but the core insight remains: for highly specialized domains like therapeutic development, there's immense value in building internal capabilities rather than relying solely on general-purpose models. 

The [full report](https://neptune.ai/state-of-foundation-model-training-report) is worth reading for anyone involved in foundation model strategy or implementation. It provides a rare, honest look at what organizations are actually doing beyond the marketing materials and benchmarks.

Thanks to the Neptune.ai team for including our perspective and for creating such a comprehensive resource for the community. The intersection of AI and therapeutic development is one of the most exciting applications of foundation models, and I'm grateful to be part of this journey.

[Keunwoo Choi](https://keunwoo.ooo) at Genentech, June 2025.
